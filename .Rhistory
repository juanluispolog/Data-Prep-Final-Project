confusionMatrix(as.factor(y_test), as.factor(pred.class))
library(keras)
library(dplyr)
library(caret)
rm(list=ls())
data("iris")
# Example using R Keras deep learning model.
# Vijay K. Gurbani, Ph.D.,
# Illinois Institute of Technology
# CS 422 (Introduction to Data Mining)
library(keras)
library(dplyr)
library(caret)
rm(list=ls())
data("iris")
# Create a new column called "label" and store the ordinal value of the
# Species there.
iris$label <- rep(0, nrow(iris))
iris$label[iris$Species == "versicolor"] <- 1
iris$label[iris$Species == "virginica"] <- 2
# Remove Species from from iris dataframe; it has been coded as an integer and
# saved in iris$label
iris$Species <- NULL
set.seed(1122)
indx <- sample(1:nrow(iris), 0.20*nrow(iris))
test.df  <- iris[indx, ]
train.df <- iris[-indx, ]
X_train <- select(train.df, -label)
y_train <- train.df$label
# Now, take the training labels, which are (1, 2, 3) corresponding to
# setosa, versicolor, and virginica, respectively, using one hot encoding.
# Thus, setosa     = 1 0 0
#       versicolor = 0 1 0
#       virginica  = 0 0 1
y_train.ohe <- to_categorical(y_train)
X_test <- select(test.df, -label)
y_test <- test.df$label
y_test.ohe <- to_categorical(test.df$label)
# When you start dealing with keras, you need to understand the R %>%
# operator.  This infix operator is not part of base R, but is defined in a
# package called magrittr, which is used in package dplyr.  This construct
# passes the LHS of the operator as the first argument to the RHS of the
# operator.  It works like the Unix pipe.
# Example:
#   > iris %>% head()
# is equivalent to head(iris).
# Or,
#   > data <- c(0.9817, 0.8765, 1.2876, 4.8765)
#   > data %>% round(3)
# What do you think the above will do?
model <- keras_model_sequential() %>%
layer_dense(units = 10, activation="relu", input_shape=c(4)) %>%
layer_dense(units = 3, activation="softmax")
model %>%
compile(loss = "categorical_crossentropy", optimizer="adam",
metrics=c("accuracy"))
model %>% fit(
data.matrix(X_train),
y_train.ohe,
epochs=300,
batch_size=5,
validation_split=0.20
)
model %>% evaluate(as.matrix(X_test), y_test.ohe)
pred.class  <- model %>% predict_classes(as.matrix(X_test))
pred.prob   <- model %>% predict(as.matrix(X_test)) %>% round(3)
confusionMatrix(as.factor(y_test), as.factor(pred.class))
setwd("/Users/juanluispolog/Google Drive/CS422/homework3")
df <- read.csv("activity-small.csv")
str(df)
library(keras)
library(dplyr)
library(caret)
rm(list=ls())
# Set working directory as needed
# Seed the PRNG
set.seed(1122)
# Scale the dataset.  We will get into the detail of why we scale in future
# lectures, however, scaling results in all of the predictors to have a
# mean of 0 and standard deviation of 1.
label <- df$label
df$label <- NULL
df <- as.data.frame(scale(df))
df$label <- label
rm(label)
# --- Your code goes below ---
index <- sample(1:nrow(df), 0.80*nrow(df))
train.df  <- iris[index, ]
test.df <- iris[-index, ]
X_train <- select(train.df, -label)
y_train <- train.df$label
# One Hot Encoding for the categorical variable
y_train.ohe <- to_categorical(y_train)
X_test <- select(test.df, -label)
y_test <- test.df$label
y_test.ohe <- to_categorical(test.df$label)
# Neural Network
model <- keras_model_sequential() %>%
layer_dense(units = 10, activation="relu", input_shape=c(4)) %>%
layer_dense(units = 3, activation="softmax")
model %>%
compile(loss = "categorical_crossentropy", optimizer="adam",
metrics=c("accuracy"))
model %>% fit(
data.matrix(X_train),
y_train.ohe,
epochs=100,
batch_size=1,
validation_split=0.20
)
# Evaluation of the Neural Network
model %>% evaluate(as.matrix(X_test), y_test.ohe)
pred.class  <- model %>% predict_classes(as.matrix(X_test))
pred.prob   <- model %>% predict(as.matrix(X_test)) %>% round(3)
confusionMatrix(as.factor(y_test), as.factor(pred.class))
setwd("/Users/juanluispolog/Google Drive/CS422/homework3")
df <- read.csv("activity-small.csv")
str(df)
library(keras)
library(dplyr)
library(caret)
rm(list=ls())
# Set working directory as needed
# Seed the PRNG
set.seed(1122)
# Scale the dataset.  We will get into the detail of why we scale in future
# lectures, however, scaling results in all of the predictors to have a
# mean of 0 and standard deviation of 1.
label <- df$label
df$label <- NULL
df <- as.data.frame(scale(df))
df$label <- label
rm(label)
setwd("/Users/juanluispolog/Google Drive/CS422/homework3")
df <- read.csv("activity-small.csv")
str(df)
library(keras)
library(dplyr)
library(caret)
rm(list=ls())
# Set working directory as needed
# Seed the PRNG
set.seed(1122)
# Scale the dataset.  We will get into the detail of why we scale in future
# lectures, however, scaling results in all of the predictors to have a
# mean of 0 and standard deviation of 1.
label <- df$label
df$label <- NULL
df <- as.data.frame(scale(df))
df$label <- label
rm(label)
df$label
df
setwd("/Users/juanluispolog/Google Drive/CS422/homework3")
df <- read.csv("activity-small.csv")
str(df)
library(keras)
library(dplyr)
library(caret)
rm(list=ls())
# Seed the PRNG
set.seed(1122)
# Scale the dataset.  We will get into the detail of why we scale in future
# lectures, however, scaling results in all of the predictors to have a
# mean of 0 and standard deviation of 1.
label <- df$label
df$label <- NULL
df <- as.data.frame(scale(df))
# Scale the dataset.  We will get into the detail of why we scale in future
# lectures, however, scaling results in all of the predictors to have a
# mean of 0 and standard deviation of 1.
label <- df$label
source('~/Google Drive/CS422/homework3/Untitled.R', echo=TRUE)
# Neural Network
model <- keras_model_sequential() %>%
layer_dense(units = 10, activation="relu", input_shape=c(4)) %>%
layer_dense(units = 4, activation="softmax")
source('~/Google Drive/CS422/homework3/Untitled.R', echo=TRUE)
source('~/Downloads/iris-nn.r', echo=TRUE)
source('~/Google Drive/CS422/homework3/Untitled.R', echo=TRUE)
source('~/Downloads/iris-nn.r', echo=TRUE)
View(X_train)
View(X_train)
X_test <- test.df[, -label]
test.df
X_test <- test.df[, -"label"]
X_test <- test.df[, -4]
source('~/Google Drive/CS422/homework3/juanluis-polo.R', echo=TRUE)
source('~/Google Drive/CS422/homework3/juanluis-polo.R', echo=TRUE)
View(test.df)
View(test.df)
source('~/Google Drive/CS422/homework3/juanluis-polo.R', echo=TRUE)
View(X_train)
source('~/Google Drive/CS422/homework3/juanluis-polo.R', echo=TRUE)
View(df)
View(test.df)
source('~/Google Drive/CS422/homework3/juanluis-polo.R', echo=TRUE)
View(X_test)
source('~/Google Drive/CS422/homework3/juanluis-polo.R', echo=TRUE)
help("layer_dense")
source('~/Google Drive/CS422/homework3/juanluis-polo.R', echo=TRUE)
batch.sizes <- c(1, 32, 64, 128, 256)
time <- c()
for (i in batch.sizes) {
begin <- Sys.time()
model <- keras_model_sequential() %>%
layer_dense(units = 10, activation = "relu", input_shape = c(3)) %>%
layer_dense(units = 4, activation = "softmax")
model %>%
compile(loss = "categorical_crossentropy", optimizer = "adam",
metrics = c("accuracy"))
model %>% fit(
data.matrix(X_train),
y_train.ohe,
epochs = 100,
batch_size = i,
validation_split = 0.20
)
end <- Sys.time()
time[i] <- begin - end
}
# Neural Network
model <- keras_model_sequential() %>%
layer_dense(units = 10, activation="relu", input_shape=c(3)) %>%
layer_dense(units = 4, activation="softmax")
model %>%
compile(loss = "categorical_crossentropy", optimizer="adam",
metrics=c("accuracy"))
model %>% fit(
data.matrix(X_train),
y_train.ohe,
epochs=100,
batch_size=1,
validation_split=0.20
)
# Evaluation of the Neural Network
model %>% evaluate(as.matrix(X_test), y_test.ohe)
pred.class  <- model %>% predict_classes(as.matrix(X_test))
pred.prob   <- model %>% predict(as.matrix(X_test)) %>% round(3)
confusionMatrix(as.factor(y_test), as.factor(pred.class))
batch.sizes <- c(1, 32, 64, 128, 256)
time <- c()
for (i in batch.sizes) {
begin <- Sys.time()
model %>% fit(
data.matrix(X_train),
y_train.ohe,
epochs = 100,
batch_size = i,
validation_split = 0.20
)
end <- Sys.time()
time[i] <- begin - end
}
time
for (i in batch.sizes) {
# begin <- Sys.time()
#   model %>% fit(
#   data.matrix(X_train),
#   y_train.ohe,
#   epochs = 100,
#   batch_size = i,
#   validation_split = 0.20
# )
#
# end <- Sys.time()
#
# time[i] <- begin - end
i
}
i
for (i in batch.sizes) {
# begin <- Sys.time()
#   model %>% fit(
#   data.matrix(X_train),
#   y_train.ohe,
#   epochs = 100,
#   batch_size = i,
#   validation_split = 0.20
# )
#
# end <- Sys.time()
#
# time[i] <- begin - end
print(i)
}
# begin <- Sys.time()
#   model %>% fit(
#   data.matrix(X_train),
#   y_train.ohe,
#   epochs = 100,
#   batch_size = i,
#   validation_split = 0.20
# )
#
# end <- Sys.time()
#
# time[i] <- begin - end
source('~/Google Drive/CS422/homework3/juanluis-polo.R', echo=TRUE)
batch.sizes <- c(1, 32, 64, 128, 256)
time <- c()
for (i in batch.sizes) {
begin <- Sys.time()
model %>% fit(
data.matrix(X_train),
y_train.ohe,
epochs = 100,
batch_size = i,
validation_split = 0.20
)
end <- Sys.time()
time[i] <- begin - end
}
source('~/Google Drive/CS422/homework3/juanluis-polo.R', echo=TRUE)
setwd("/juanluispolog/OneDrive - Universidad Politécnica de Madrid/06 MCS/CSP_DataPrepAnalysis/project/DataPrep")
getwd()
setwd("/Users/juanluispolog/OneDrive - Universidad Politécnica de Madrid/
06 MCS/CSP_DataPrepAnalysis/project/DataPrep")
setwd("/Users/juanluispolog/OneDrive - Universidad Politécnica de Madrid/
06 MCS/CSP571_DataPrepAnalysis/project/DataPrep")
setwd("/Users/juanluispolog/OneDrive - Universidad Politécnica de Madrid")
setwd("/Users/juanluispolog/OneDrive - Universidad Politécnica de Madrid/JUAN LUIS/
06 MCS/CSP571_DataPrepAnalysis/project/DataPrep")
setwd("/Users/juanluispolog/OneDrive - Universidad Politécnica de Madrid/JUAN LUIS/06 MCS/CSP571_DataPrepAnalysis/project/DataPrep")
getwd()
premier.1516 <- read.csv("premier-15-16")
premier.1516 <- read.csv("premier-15-16.cvs")
getwd()
ls
premier.16.17 <- read.csv("premier-16-17.cvs")
premier.15.16 <- read.csv(premier-15-16.cvs)
premier.16.17 <- read.csv("premier-16-17.cvs")
premier.15.16 <- read.csv("premier-15-16.csv")
c
premier.16.17 <- read.csv("premier-16-17.csv")
premier.16.17 <- read.csv("premier-16-17.csv")
df.15.16 <- read.csv("premier-15-16.csv")
df.16.17 <- read.csv("premier-16-17.csv")
df.17.18 <- read.csv("premier-17-18.csv")
df.18.19 <- read.csv("premier-18-19.csv")
df.19.20 <- read.csv("premier-19-20.csv")
source('~/OneDrive - Universidad Politécnica de Madrid/JUAN LUIS/06 MCS/CSP571_DataPrepAnalysis/project/DataPrep/datasetCleaning.R', echo=TRUE)
source('~/OneDrive - Universidad Politécnica de Madrid/JUAN LUIS/06 MCS/CSP571_DataPrepAnalysis/project/DataPrep/datasetCleaning.R', echo=TRUE)
str(df.15.16)
which(df.15.16, colnames(df.15.16)=="B365H")
colnames(df.15.16)
which(colnames(df.15.16) == "B365H")
ncol(df.15.16)
df.15.16 <- df.15.16[, which(colnames(df.15.16) == "B365H"):ncol(df.15.16)]
View(df.15.16)
source('~/OneDrive - Universidad Politécnica de Madrid/JUAN LUIS/06 MCS/CSP571_DataPrepAnalysis/project/DataPrep/datasetCleaning.R', echo=TRUE)
source('~/OneDrive - Universidad Politécnica de Madrid/JUAN LUIS/06 MCS/CSP571_DataPrepAnalysis/project/DataPrep/datasetCleaning.R', echo=TRUE)
df.15.16 <- df.15.16[, -1:5]
df.15.16 <- df.15.16[, -1]
source('~/OneDrive - Universidad Politécnica de Madrid/JUAN LUIS/06 MCS/CSP571_DataPrepAnalysis/project/DataPrep/datasetCleaning.R', echo=TRUE)
df.15.16 <- df.15.16[, - c(which(colnames(df.15.16) == "B365H"):ncol(df.15.16))]
View(df.15.16)
View(df.15.16)
View(df.16.17)
View(df.17.18)
View(df.18.19)
View(df.19.20)
View(df.17.18)
source('~/OneDrive - Universidad Politécnica de Madrid/JUAN LUIS/06 MCS/CSP571_DataPrepAnalysis/project/DataPrep/datasetCleaning.R', echo=TRUE)
str(df.15.16)
str(df.15.16)
str(df.15.16)
source('~/OneDrive - Universidad Politécnica de Madrid/JUAN LUIS/06 MCS/CSP571_DataPrepAnalysis/project/DataPrep/datasetCleaning.R', echo=TRUE)
df.19.20$Time
# Removing Time attribute from df.19.20 season, since other df do not store this information
df.19.20 <- df.19.20[, -colnames(df.19.20)[=="Time"]]
# Removing Time attribute from df.19.20 season, since other df do not store this information
df.19.20 <- df.19.20[, -colnames(df.19.20)["Time"]]
colnames(df.19.20)["Time"]
colnames(df.19.20) == "Time"
which(colnames(df.19.20) == "Time")
# Removing Time attribute from df.19.20 season, since other df do not store this information
df.19.20 <- df.19.20[, - which(colnames(df.19.20) == "Time")]
df.15.16$Date
split(df.15.16$Date, "/")
date <- format(df.15.16$Date, "%D/%M/%Y")
as.Date(df.15.16$Date)
as.Date(df.15.16$Date, "%D-%M-%Y")
as.Date(df.15.16$Date, "%d-%m-%y")
as.Date(df.15.16$Date, "%d/%m/%y")
View(df.15.16)
date <- > as.Date(df.15.16$Date, "%d/%m/%y")
date
date <- as.Date(df.15.16$Date, "%d/%m/%y")
date
date.df <- date.fr
date.df <- data.frame(as.Date(df.15.16$Date, "%d/%m/%y"))
date.df
date.df <- data.frame(yyyy = as.numeric(format(datetxt, format = "%Y"))
date.df
date.df <- data.frame(yyyy = as.numeric(format(datetxt, format = "%Y")))
date.df <- data.frame(yyyy = as.numeric(format(date, format = "%Y")))
date.df
date.df <- data.frame(yyyy = as.numeric(format(date, format = "%Y")), as.numeric(format(datetxt, format = "%M"), as.numeric(format(datetxt, format = "%D"))
date.df <- data.frame(yyyy = as.numeric(format(date, format = "%Y")), as.numeric(format(datetxt, format = "%M")), as.numeric(format(datetxt, format = "%D")))
date.df <- data.frame(yyyy = as.numeric(format(date, format = "%Y")), as.numeric(format(date, format = "%M")), as.numeric(format(date, format = "%D")))
date.df <- data.frame(yyyy = as.numeric(format(date, format = "%Y")),
mm= as.numeric(format(date, format = "%M")),
dd = as.numeric(format(date, format = "%D"))
)
date.df <- data.frame(yyyy = as.numeric(format(date, format = "%Y")),
mm= as.numeric(format(date, format = "%M")),
dd = as.numeric(format(date, format = "%D"))
)
date.df
date.df <- data.frame(yyyy = as.numeric(format(date, format = "%y")),
mm= as.numeric(format(date, format = "%m")),
dd = as.numeric(format(date, format = "%d"))
)
date.df
date.df <- data.frame(yyyy = as.numeric(format(date, format = "%yyyy")),
mm= as.numeric(format(date, format = "%mm")),
dd = as.numeric(format(date, format = "%dd"))
)
help("as.numeric")
date.df <- data.frame(yyyy = as.numeric(format(date, format = "%Y")),
mm= as.numeric(format(date, format = "%m")),
dd = as.numeric(format(date, format = "%d"))
)
date.df
date.df <- data.frame(yyyy = as.numeric(format(date, format = "%Y")),
mm= as.numeric(format(date, format = "%m")),
dd = as.numeric(format(date, format = "%d"))
)
date.df
date <- as.Date(df.15.16$Date)
date <- as.Date(df.15.16$Date)
date.df <- data.frame(yyyy = as.numeric(format(date, format = "%Y")),
mm= as.numeric(format(date, format = "%m")),
dd = as.numeric(format(date, format = "%d"))
)
date <- as.Date(df[1]$Date)
date <- as.Date(df[[1]]$Date)
df <- c(df.15.16, df.16.17, df.17.18, df.18.19, df.18.19)
date <- as.Date(df[[1]]$Date)
date <- as.Date(df[1]$Date)
df
df[1]
View(df)
View(df)
df <- data.frame(df.15.16, df.16.17, df.17.18, df.18.19, df.18.19)
df
View(df)
rm(list=ls())
setwd("/Users/juanluispolog/OneDrive - Universidad Politécnica de Madrid/JUAN LUIS/06 MCS/CSP571_DataPrepAnalysis/project/DataPrep")
df.15.16 <- read.csv("premier-15-16.csv")
df.16.17 <- read.csv("premier-16-17.csv")
df.17.18 <- read.csv("premier-17-18.csv")
df.18.19 <- read.csv("premier-18-19.csv")
df.19.20 <- read.csv("premier-19-20.csv")
str(df.15.16)
# Removing betting attributes from datasets
df.15.16 <- df.15.16[, - c(which(colnames(df.15.16) == "B365H"):ncol(df.15.16))]
df.16.17 <- df.16.17[, - c(which(colnames(df.16.17) == "B365H"):ncol(df.16.17))]
df.17.18 <- df.17.18[, - c(which(colnames(df.17.18) == "B365H"):ncol(df.17.18))]
df.18.19 <- df.18.19[, - c(which(colnames(df.18.19) == "B365H"):ncol(df.18.19))]
df.19.20 <- df.19.20[, - c(which(colnames(df.19.20) == "B365H"):ncol(df.19.20))]
str(df.15.16)
str(df.16.17)
str(df.17.18)
str(df.18.19)
str(df.18.19)
class(df.15.16)
# Homogeneizing Date attribute: yyyy/mm/dd
df.list <- c(df.15.16, df.16.17)
# Homogeneizing Date attribute: yyyy/mm/dd
df.list <- list(df.15.16, df.16.17)
# Homogeneizing Date attribute: yyyy/mm/dd
df.list <- list(df.15.16, df.16.17, df.17.18, df.18.19, df.19.20)
df.list
df.list[1]
date <- as.Date(df.list[1]$Date)
date <- as.Date(df.list[[1]]$Date)
date
date <- as.Date(df.list[[1]]$Date, format = "%Y/%m/%d")
date
date <- as.Date(df.list[[1]]$Date, format = "%y/%m/%d")
date
date.df <- data.frame(yyyy = as.numeric(format(date, format = "%Y")),
mm= as.numeric(format(date, format = "%m")),
dd = as.numeric(format(date, format = "%d"))
)
df.15.16$Date<-date.df
df.15.16
str(df.15.16)
str(df.15.16)
str(df.15.16)
c(which(colnames(df.15.16) == "homeTeam"):ncol(df.15.16))
c(which(colnames(df.15.16) == "HomeTeam"):ncol(df.15.16))
source('~/OneDrive - Universidad Politécnica de Madrid/JUAN LUIS/06 MCS/CSP571_DataPrepAnalysis/project/DataPrep/datasetCleaning.R', echo=TRUE)
length(df.list)
df.list[[i]]
df.list[i]
df.list[i]
df.list[[i]] <- data.frame(df.list[[i]]$Div, date.df, df.list[[i]][, c(3:23)])
df.list
df.list[[1]]
df.list[[i]]
source('~/OneDrive - Universidad Politécnica de Madrid/JUAN LUIS/06 MCS/CSP571_DataPrepAnalysis/project/DataPrep/datasetCleaning.R', echo=TRUE)
df.15.16 <- df.list[[1]]
df.16.17 <- df.list[[2]]
df.17.18 <- df.list[[3]]
df.18.19 <- df.list[[4]]
df.19.20 <- df.list[[5]]
source('~/OneDrive - Universidad Politécnica de Madrid/JUAN LUIS/06 MCS/CSP571_DataPrepAnalysis/project/DataPrep/datasetCleaning.R', echo=TRUE)
df <- rbind(df.15.16, df.16.17, df.17.18, df.18.19, df.19.20)
source('~/OneDrive - Universidad Politécnica de Madrid/JUAN LUIS/06 MCS/CSP571_DataPrepAnalysis/project/DataPrep/datasetCleaning.R', echo=TRUE)
